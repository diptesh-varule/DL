{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9f0RSeUJLP1"
   },
   "source": [
    "*Problem Statement:*\n",
    "\n",
    "    Implement anomaly detection for given credit card dataset using Autoencoder and build the model by using the following steps:\n",
    "    a.\tImport required libraries\n",
    "    b.\tUpload / access the dataset\n",
    "    c.\tEncoder converts it into latent representation\n",
    "    d.\tDecoder networks convert it back to the original input\n",
    "    e.\tCompile the models with Optimizer, Loss, and Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEl3ncgPc0sv"
   },
   "source": [
    "\n",
    "#Credit Card Fraud Detection\n",
    "\n",
    "Example of outlier detection with autoencoders. Dataset https://www.kaggle.com/mlg-ulb/creditcardfraud from Machine Learning Group (http://mlg.ulb.ac.be) of ULB (UniversitÃ© Libre de Bruxelles).\n",
    "\n",
    "It is a highly unbalanced dataset with a very low percetnage of fraudulent credit card transactions. Our purpose is to build a classifier for detecting fraudulent transactions. In this example we will consider them as outliers an will use an autoencoder for detecting them.\n",
    "\n",
    "##Downloading of dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OV8v985dDi6"
   },
   "source": [
    "##Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "id": "C-vN7SvXvMs5",
    "outputId": "d0c3b824-37dc-41ee-f53f-33d3aed20442"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp9PNETFd2G4"
   },
   "source": [
    "##Loading dataset in Python and taking a first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "NMVr2-hzvlID",
    "outputId": "c5d8f7c4-825b-40fd-cbb7-edc9a05804c4"
   },
   "outputs": [],
   "source": [
    "dat=pd.read_csv('creditcard.csv')\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y0a-xNMeDEA"
   },
   "source": [
    "The dataset is highly unbalanced with very few fraudulent credit cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "l3TwIbGCvmz9",
    "outputId": "1846477b-f926-4228-abe7-50146d09f04d"
   },
   "outputs": [],
   "source": [
    "dat['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "L4KRErdPvt1A",
    "outputId": "95e08e75-11e6-47f8-c377-4d3e7895728d"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Class',data=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDJt4sXDvxzb"
   },
   "outputs": [],
   "source": [
    "dat = dat.drop(['Time'], 1)\n",
    "dat['Amount'] = StandardScaler().fit_transform(dat['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vTh-X3beLk_"
   },
   "source": [
    "Splitting into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1T3X-3wFv001"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dat.drop('Class',1) , dat['Class'], test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "ooXM9UEwv3QX",
    "outputId": "0de04af5-f7fc-4d25-a8ed-1b349703a8ef"
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "K3YUftDjv5z-",
    "outputId": "247b9428-51e2-4c19-b3ac-398955f36455"
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otvOl-HcevoG"
   },
   "source": [
    "##First method: using autoencoder's regression error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPpRAl0TeQR8"
   },
   "source": [
    "For our first example we will train our autoencoder only on non fraudulent cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMzBdaAdv7rE"
   },
   "outputs": [],
   "source": [
    "X_train_normal = X_train[y_train==0]\n",
    "X_train_fraud = X_train[y_train==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbX1U5aheSla"
   },
   "source": [
    "Building an autoencoder with\n",
    "- an input layer with 29 neurons,\n",
    "- a hidden layer with 12 neurons,\n",
    "- an output layer with 29 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "euBPgiamw2R6",
    "outputId": "afd64cdc-dcf4-4595-9496-cc3b0d89fa0d"
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(29, ))\n",
    "encoded = Dense(12,activation='tanh')(input_layer)\n",
    "decoded = Dense(29,activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_layer,decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "fY42GWDWyoxL",
    "outputId": "ba09f0c7-e251-47c0-a269-f4af57513e33"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZC2j3eXJxM-B",
    "outputId": "87fb0776-1173-4a98-cd16-dd8da40fae7a"
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(X_train_normal, X_train_normal, epochs = 10, batch_size=128,validation_data=(X_train_normal,X_train_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "qzcu7y3nxsw3",
    "outputId": "d1f73fe7-8c35-402d-9123-c63bf2d2a8f7"
   },
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(X_train)\n",
    "mse = np.mean(np.power(X_train - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_train})\n",
    "error_df.groupby('true_class').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRQepwFre9UM"
   },
   "source": [
    "As we can see above the error for non fraudulent case is lower than the error for fraudulent cases. We use a threshold of mean plus 3 sds to classify the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zAII8DQxw-B"
   },
   "outputs": [],
   "source": [
    "test_predictions=autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - test_predictions, 2), axis=1)\n",
    "y_pred=[(lambda er: 1 if er>=11.078922  else 0)(er) for er in mse]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "mZ4V1lfb46jQ",
    "outputId": "ddd09775-e18f-411a-bf83-4204e1a7bfef"
   },
   "outputs": [],
   "source": [
    "conf_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "ax=plt.subplot()\n",
    "sns.heatmap(conf_matrix,annot=True,ax=ax,fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
    "ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Normal', 'Fraud']); ax.yaxis.set_ticklabels(['Normal', 'Fraud']);\n",
    "ax.set(yticks=[0, 2], \n",
    "       xticks=[0.5, 1.5])\n",
    "ax.yaxis.set_major_locator(ticker.IndexLocator(base=1, offset=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
